{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *\n",
    "from tokeniser import *\n",
    "from process_blog_csv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs = get_blogs(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = Subword_Tokeniser()\n",
    "tokeniser.fit_on_text_BPE(blogs[:100],300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 256\n",
    "vocab_size = tokeniser.vocab\n",
    "embedding_height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================>]\r"
     ]
    }
   ],
   "source": [
    "x,y = blogs_to_train(tokeniser,blogs,100000,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(vocab_size,embedding_height,mask_zero = True,input_length = window_size))\n",
    "model.add(Positional_Encode())\n",
    "model.add(Transformer_Block(embedding_height,window_size = window_size))\n",
    "model.add(Transformer_Block(embedding_height,window_size = window_size))\n",
    "model.add(Transformer_Block(embedding_height,window_size = window_size))\n",
    "model.add(Dense(vocab_size,activation = \"softmax\"))\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\",optimizer = \"adam\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 6717s 2s/step - loss: 3.7125 - accuracy: 0.1866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14f54d12400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x).astype(\"float32\"),np.array(y).astype(\"int32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 6249s 2s/step - loss: 3.0468 - accuracy: 0.2958\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 6252s 2s/step - loss: 2.6022 - accuracy: 0.3875\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 6235s 2s/step - loss: 2.3293 - accuracy: 0.4463\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 6263s 2s/step - loss: 2.1436 - accuracy: 0.4866\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 7010s 2s/step - loss: 2.0112 - accuracy: 0.5161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14f01370c40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x).astype(\"float32\"),np.array(y).astype(\"int32\"),epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, layer_normalization_12_layer_call_fn, layer_normalization_12_layer_call_and_return_conditional_losses, layer_normalization_13_layer_call_fn, layer_normalization_13_layer_call_and_return_conditional_losses while saving (showing 5 of 115). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gbt-256x128\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gbt-256x128\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"gbt-256x128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think I am going... leeat these boatched these are you! If why, oily constantsot, Li did! Nichollected that amounty belbitter that there to be fter was so many sing..n'd for the ghed ch her heads thing seem son,&BU2 dride at the gintroke a nutes to be ht thice. 62 d (as \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"I think I am going... leeat these boatched these are you! If why, oily constantsot, Li did! Nichollected that amounty belbitter that there to be fter was so many sing..n'd for the ghed ch her heads thing seem son,&BU2 dride at the gintroke a nutes to be ht thice. 62 d (as \"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(input_sentence,new_tokens):\n",
    "    encoded_text = tokeniser.encode([input_sentence])[0][:-1]\n",
    "\n",
    "    for i in range(new_tokens):\n",
    "        padding = [0 for _ in range(window_size - len(encoded_text))]\n",
    "        padding.extend(encoded_text)\n",
    "        inputs = np.array(padding).reshape(1,window_size)\n",
    "\n",
    "        outputs = model.predict(inputs,verbose = False)[0]\n",
    "        outputs[-1][np.argmax(outputs[-1])] = 0\n",
    "        encoded_text.append(np.argmax(outputs[-1]))\n",
    "\n",
    "        print(tokeniser.decode([encoded_text])[0],end = \"\\r\")\n",
    "\n",
    "    return tokeniser.decode([encoded_text])\n",
    "\n",
    "generate(\"I think I am going \",100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1770a777f8a707a68323ad32b77ca7cbf6452a898f6348625ef54424c6744df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
